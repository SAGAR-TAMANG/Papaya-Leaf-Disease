{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da648a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Section 2: Loading Saved Models ---\n",
      "Successfully loaded ResNet50V2 model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,245</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │        \u001b[38;5;34m10,245\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,595,537</span> (90.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,595,537\u001b[0m (90.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,245</span> (40.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,245\u001b[0m (40.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> (89.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,564,800\u001b[0m (89.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,492</span> (80.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m20,492\u001b[0m (80.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded Swin Transformer model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ swin_backbone_layer_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinBackboneLayer</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ swin_backbone_layer_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m768\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSwinBackboneLayer\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m3,845\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,537</span> (45.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,537\u001b[0m (45.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> (15.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,845\u001b[0m (15.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,692</span> (30.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m7,692\u001b[0m (30.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ResNet50V2 model with dummy input.\n",
      "CNN model output shape: (1, 5)\n",
      "CNN model has defined output: False\n",
      "CNN model output shape (attribute): (None, 5)\n",
      "Layers in ResNet50V2 backbone:\n",
      "input_layer\n",
      "conv1_pad\n",
      "conv1_conv\n",
      "pool1_pad\n",
      "pool1_pool\n",
      "conv2_block1_preact_bn\n",
      "conv2_block1_preact_relu\n",
      "conv2_block1_1_conv\n",
      "conv2_block1_1_bn\n",
      "conv2_block1_1_relu\n",
      "conv2_block1_2_pad\n",
      "conv2_block1_2_conv\n",
      "conv2_block1_2_bn\n",
      "conv2_block1_2_relu\n",
      "conv2_block1_0_conv\n",
      "conv2_block1_3_conv\n",
      "conv2_block1_out\n",
      "conv2_block2_preact_bn\n",
      "conv2_block2_preact_relu\n",
      "conv2_block2_1_conv\n",
      "conv2_block2_1_bn\n",
      "conv2_block2_1_relu\n",
      "conv2_block2_2_pad\n",
      "conv2_block2_2_conv\n",
      "conv2_block2_2_bn\n",
      "conv2_block2_2_relu\n",
      "conv2_block2_3_conv\n",
      "conv2_block2_out\n",
      "conv2_block3_preact_bn\n",
      "conv2_block3_preact_relu\n",
      "conv2_block3_1_conv\n",
      "conv2_block3_1_bn\n",
      "conv2_block3_1_relu\n",
      "conv2_block3_2_pad\n",
      "conv2_block3_2_conv\n",
      "conv2_block3_2_bn\n",
      "conv2_block3_2_relu\n",
      "max_pooling2d\n",
      "conv2_block3_3_conv\n",
      "conv2_block3_out\n",
      "conv3_block1_preact_bn\n",
      "conv3_block1_preact_relu\n",
      "conv3_block1_1_conv\n",
      "conv3_block1_1_bn\n",
      "conv3_block1_1_relu\n",
      "conv3_block1_2_pad\n",
      "conv3_block1_2_conv\n",
      "conv3_block1_2_bn\n",
      "conv3_block1_2_relu\n",
      "conv3_block1_0_conv\n",
      "conv3_block1_3_conv\n",
      "conv3_block1_out\n",
      "conv3_block2_preact_bn\n",
      "conv3_block2_preact_relu\n",
      "conv3_block2_1_conv\n",
      "conv3_block2_1_bn\n",
      "conv3_block2_1_relu\n",
      "conv3_block2_2_pad\n",
      "conv3_block2_2_conv\n",
      "conv3_block2_2_bn\n",
      "conv3_block2_2_relu\n",
      "conv3_block2_3_conv\n",
      "conv3_block2_out\n",
      "conv3_block3_preact_bn\n",
      "conv3_block3_preact_relu\n",
      "conv3_block3_1_conv\n",
      "conv3_block3_1_bn\n",
      "conv3_block3_1_relu\n",
      "conv3_block3_2_pad\n",
      "conv3_block3_2_conv\n",
      "conv3_block3_2_bn\n",
      "conv3_block3_2_relu\n",
      "conv3_block3_3_conv\n",
      "conv3_block3_out\n",
      "conv3_block4_preact_bn\n",
      "conv3_block4_preact_relu\n",
      "conv3_block4_1_conv\n",
      "conv3_block4_1_bn\n",
      "conv3_block4_1_relu\n",
      "conv3_block4_2_pad\n",
      "conv3_block4_2_conv\n",
      "conv3_block4_2_bn\n",
      "conv3_block4_2_relu\n",
      "max_pooling2d_1\n",
      "conv3_block4_3_conv\n",
      "conv3_block4_out\n",
      "conv4_block1_preact_bn\n",
      "conv4_block1_preact_relu\n",
      "conv4_block1_1_conv\n",
      "conv4_block1_1_bn\n",
      "conv4_block1_1_relu\n",
      "conv4_block1_2_pad\n",
      "conv4_block1_2_conv\n",
      "conv4_block1_2_bn\n",
      "conv4_block1_2_relu\n",
      "conv4_block1_0_conv\n",
      "conv4_block1_3_conv\n",
      "conv4_block1_out\n",
      "conv4_block2_preact_bn\n",
      "conv4_block2_preact_relu\n",
      "conv4_block2_1_conv\n",
      "conv4_block2_1_bn\n",
      "conv4_block2_1_relu\n",
      "conv4_block2_2_pad\n",
      "conv4_block2_2_conv\n",
      "conv4_block2_2_bn\n",
      "conv4_block2_2_relu\n",
      "conv4_block2_3_conv\n",
      "conv4_block2_out\n",
      "conv4_block3_preact_bn\n",
      "conv4_block3_preact_relu\n",
      "conv4_block3_1_conv\n",
      "conv4_block3_1_bn\n",
      "conv4_block3_1_relu\n",
      "conv4_block3_2_pad\n",
      "conv4_block3_2_conv\n",
      "conv4_block3_2_bn\n",
      "conv4_block3_2_relu\n",
      "conv4_block3_3_conv\n",
      "conv4_block3_out\n",
      "conv4_block4_preact_bn\n",
      "conv4_block4_preact_relu\n",
      "conv4_block4_1_conv\n",
      "conv4_block4_1_bn\n",
      "conv4_block4_1_relu\n",
      "conv4_block4_2_pad\n",
      "conv4_block4_2_conv\n",
      "conv4_block4_2_bn\n",
      "conv4_block4_2_relu\n",
      "conv4_block4_3_conv\n",
      "conv4_block4_out\n",
      "conv4_block5_preact_bn\n",
      "conv4_block5_preact_relu\n",
      "conv4_block5_1_conv\n",
      "conv4_block5_1_bn\n",
      "conv4_block5_1_relu\n",
      "conv4_block5_2_pad\n",
      "conv4_block5_2_conv\n",
      "conv4_block5_2_bn\n",
      "conv4_block5_2_relu\n",
      "conv4_block5_3_conv\n",
      "conv4_block5_out\n",
      "conv4_block6_preact_bn\n",
      "conv4_block6_preact_relu\n",
      "conv4_block6_1_conv\n",
      "conv4_block6_1_bn\n",
      "conv4_block6_1_relu\n",
      "conv4_block6_2_pad\n",
      "conv4_block6_2_conv\n",
      "conv4_block6_2_bn\n",
      "conv4_block6_2_relu\n",
      "max_pooling2d_2\n",
      "conv4_block6_3_conv\n",
      "conv4_block6_out\n",
      "conv5_block1_preact_bn\n",
      "conv5_block1_preact_relu\n",
      "conv5_block1_1_conv\n",
      "conv5_block1_1_bn\n",
      "conv5_block1_1_relu\n",
      "conv5_block1_2_pad\n",
      "conv5_block1_2_conv\n",
      "conv5_block1_2_bn\n",
      "conv5_block1_2_relu\n",
      "conv5_block1_0_conv\n",
      "conv5_block1_3_conv\n",
      "conv5_block1_out\n",
      "conv5_block2_preact_bn\n",
      "conv5_block2_preact_relu\n",
      "conv5_block2_1_conv\n",
      "conv5_block2_1_bn\n",
      "conv5_block2_1_relu\n",
      "conv5_block2_2_pad\n",
      "conv5_block2_2_conv\n",
      "conv5_block2_2_bn\n",
      "conv5_block2_2_relu\n",
      "conv5_block2_3_conv\n",
      "conv5_block2_out\n",
      "conv5_block3_preact_bn\n",
      "conv5_block3_preact_relu\n",
      "conv5_block3_1_conv\n",
      "conv5_block3_1_bn\n",
      "conv5_block3_1_relu\n",
      "conv5_block3_2_pad\n",
      "conv5_block3_2_conv\n",
      "conv5_block3_2_bn\n",
      "conv5_block3_2_relu\n",
      "conv5_block3_3_conv\n",
      "conv5_block3_out\n",
      "post_bn\n",
      "post_relu\n",
      "Error initializing CNN model with dummy input: 'Activation' object has no attribute 'output_shape'\n",
      "Initialized Swin Transformer model with dummy input.\n",
      "Transformer model output shape: (1, 5)\n",
      "\n",
      "--- Section 3: Defining Grad-CAM Logic ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: swin_backbone_layer_21. Existing layers are: ['input_layer', 'swin_backbone_layer_22', 'global_average_pooling1d', 'dropout', 'dense'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 149\u001b[39m\n\u001b[32m    146\u001b[39m img_array_transformer_norm = img_array_transformer / \u001b[32m255.0\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# Get the individual layers of the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m swin_backbone_layer = \u001b[43mtransformer_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_layer_name_transformer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m global_pool_layer = transformer_model.get_layer(\u001b[33m\"\u001b[39m\u001b[33mglobal_average_pooling1d\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    151\u001b[39m dense_layer = transformer_model.get_layer(\u001b[33m\"\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# Assuming the last dense layer is named 'dense'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TAMANG\\Documents\\GitHub\\Papaya-Leaf-Disease\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TAMANG\\Documents\\GitHub\\Papaya-Leaf-Disease\\venv\\Lib\\site-packages\\keras\\src\\models\\model.py:210\u001b[39m, in \u001b[36mModel.get_layer\u001b[39m\u001b[34m(self, name, index)\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m layer.name == name:\n\u001b[32m    209\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    211\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Existing layers are: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    212\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer.name\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlayer\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mProvide either a layer name or layer index at `get_layer`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: No such layer: swin_backbone_layer_21. Existing layers are: ['input_layer', 'swin_backbone_layer_22', 'global_average_pooling1d', 'dropout', 'dense']."
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# FINAL SCRIPT: INTERPRETABILITY ANALYSIS WITH GRAD-CAM\n",
    "# ==============================================================================\n",
    "# This script loads previously saved CNN and Transformer models and applies\n",
    "# Grad-CAM to visualize what parts of the image each model focuses on.\n",
    "#\n",
    "# INSTRUCTIONS:\n",
    "# 1. Ensure you have the following saved model files in your Colab session:\n",
    "#    - papaya_disease_resnet50v2.keras\n",
    "#    - papaya_disease_swin_transformer.keras\n",
    "# 2. You will also need the 'papaya_data_split_vit' directory from the last run.\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# --- 1. RE-DEFINE THE CUSTOM SWIN LAYER FOR MODEL LOADING ---\n",
    "# Keras needs this definition to know how to load the saved Swin model.\n",
    "# This code is a simplified version from your successful training script.\n",
    "from transformers import SwinModel\n",
    "import torch\n",
    "\n",
    "class SwinBackboneLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_name=\"microsoft/swin-tiny-patch4-window7-224\", **kwargs):\n",
    "        super(SwinBackboneLayer, self).__init__(**kwargs)\n",
    "        self.swin = SwinModel.from_pretrained(model_name)\n",
    "        self.swin.eval()\n",
    "        for param in self.swin.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        def swin_forward(inp):\n",
    "            input_np = inp.numpy()\n",
    "            inputs_torch = torch.from_numpy(input_np).permute(0, 3, 1, 2)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.swin(inputs_torch).last_hidden_state\n",
    "            return outputs.detach().numpy()\n",
    "        output = tf.py_function(func=swin_forward, inp=[inputs], Tout=tf.float32)\n",
    "        output.set_shape([None, 49, 768])\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        # Implement get_config to allow model saving/loading\n",
    "        config = super(SwinBackboneLayer, self).get_config()\n",
    "        # You can add model_name or other parameters to the config if needed\n",
    "        return config\n",
    "\n",
    "\n",
    "# --- 2. SETUP AND MODEL LOADING ---\n",
    "print(\"\\n--- Section 2: Loading Saved Models ---\")\n",
    "\n",
    "# Define necessary constants\n",
    "SPLIT_BASE_DIR = pathlib.Path('papaya_data_split_vit')\n",
    "test_dir = SPLIT_BASE_DIR / \"test\"\n",
    "CLASS_NAMES = sorted([item.name for item in test_dir.glob(\"*\") if item.is_dir()])\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Load the CNN model (ResNet50V2)\n",
    "cnn_model = None  # Initialize to None\n",
    "try:\n",
    "    cnn_model = tf.keras.models.load_model(\"papaya_disease_resnet50v2.keras\")\n",
    "    print(\"Successfully loaded ResNet50V2 model.\")\n",
    "    cnn_model.summary()  # Print model summary\n",
    "except Exception as e:\n",
    "    print(f\"Could not load ResNet50V2 model. Error: {e}\")\n",
    "\n",
    "# Load the Transformer model (Swin)\n",
    "transformer_model = None  # Initialize to None\n",
    "try:\n",
    "    transformer_model = tf.keras.models.load_model(\n",
    "        \"papaya_disease_swin_transformer.keras\",\n",
    "        custom_objects={\"SwinBackboneLayer\": SwinBackboneLayer}\n",
    "    )\n",
    "    print(\"Successfully loaded Swin Transformer model.\")\n",
    "    transformer_model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Could not load Swin Transformer model. Error: {e}\")\n",
    "\n",
    "# Build and initialize the CNN model\n",
    "if cnn_model:\n",
    "    if not cnn_model.built:\n",
    "        cnn_model.build((None, 224, 224, 3))\n",
    "        print(\"Built ResNet50V2 model.\")\n",
    "    # Force initialization by passing a dummy input\n",
    "    try:\n",
    "        dummy_input = tf.zeros((1, 224, 224, 3))\n",
    "        output = cnn_model(dummy_input)  # Call the model to initialize all layers\n",
    "        print(\"Initialized ResNet50V2 model with dummy input.\")\n",
    "        print(f\"CNN model output shape: {output.shape}\")\n",
    "        # Verify model output is defined\n",
    "        print(f\"CNN model has defined output: {hasattr(cnn_model, 'output')}\")\n",
    "        print(f\"CNN model output shape (attribute): {cnn_model.output_shape}\")\n",
    "        # Print layer names for verification\n",
    "        try:\n",
    "            base_model = cnn_model.get_layer(\"resnet50v2\")\n",
    "            print(\"Layers in ResNet50V2 backbone:\")\n",
    "            for layer in base_model.layers:\n",
    "                print(layer.name)\n",
    "            # Verify post_relu layer\n",
    "            try:\n",
    "                post_relu_layer = base_model.get_layer(\"post_relu\")\n",
    "                print(f\"post_relu layer found with output shape: {post_relu_layer.output_shape}\")\n",
    "            except ValueError as e:\n",
    "                print(f\"Error: post_relu layer not found in resnet50v2. Error: {e}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error accessing resnet50v2 layer: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing CNN model with dummy input: {e}\")\n",
    "else:\n",
    "    print(\"CNN model not loaded, skipping initialization.\")\n",
    "\n",
    "# Build and initialize the Transformer model\n",
    "if transformer_model:\n",
    "    if not transformer_model.built:\n",
    "        transformer_model.build((None, 224, 224, 3))\n",
    "        print(\"Built Swin Transformer model.\")\n",
    "    try:\n",
    "        dummy_input = tf.zeros((1, 224, 224, 3))\n",
    "        output = transformer_model(dummy_input / 255.0)  # Normalize for Transformer\n",
    "        print(\"Initialized Swin Transformer model with dummy input.\")\n",
    "        print(f\"Transformer model output shape: {output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Transformer model with dummy input: {e}\")\n",
    "else:\n",
    "    print(\"Transformer model not loaded, skipping initialization.\")\n",
    "\n",
    "# --- 3. GRAD-CAM IMPLEMENTATION ---\n",
    "print(\"\\n--- Section 3: Defining Grad-CAM Logic ---\")\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    \"\"\"Loads and preprocesses a single image.\"\"\"\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=size)\n",
    "    array = tf.keras.utils.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "# --- Transformer Visualization ---\n",
    "if transformer_model and last_layer_name_transformer:\n",
    "    img_array_transformer = get_img_array(img_path_str, size=IMG_SIZE)\n",
    "    # The Swin Transformer expects inputs normalized to [0, 1]\n",
    "    img_array_transformer_norm = img_array_transformer / 255.0\n",
    "\n",
    "    # Get the individual layers of the model\n",
    "    swin_backbone_layer = transformer_model.get_layer(last_layer_name_transformer)\n",
    "    global_pool_layer = transformer_model.get_layer(\"global_average_pooling1d\")\n",
    "    dense_layer = transformer_model.get_layer(\"dense\") # Assuming the last dense layer is named 'dense'\n",
    "\n",
    "    # Use GradientTape to manually watch the backbone's output\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1. Get the output from the custom Swin layer\n",
    "        transformer_output = swin_backbone_layer(img_array_transformer_norm)\n",
    "        # 2. IMPORTANT: Explicitly watch this tensor\n",
    "        tape.watch(transformer_output)\n",
    "        # 3. Manually pass the output through the rest of the model\n",
    "        x = global_pool_layer(transformer_output)\n",
    "        # The dropout layer is often skipped during inference/explanation\n",
    "        preds = dense_layer(x)\n",
    "        \n",
    "        # Get the specific prediction for the top class\n",
    "        pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # Calculate the gradient of the top predicted class w.r.t the backbone's output\n",
    "    grads = tape.gradient(class_channel, transformer_output)\n",
    "\n",
    "    if grads is not None:\n",
    "        # --- FIX #2: Corrected averaging axis for Grad-CAM ---\n",
    "        # Pool the gradients across the patch dimension (49) to get a single weight per feature channel (768)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "        transformer_output = transformer_output[0]\n",
    "        # Multiply each patch's feature vector by its corresponding gradient-weight\n",
    "        heatmap_transformer = transformer_output @ pooled_grads[..., tf.newaxis]\n",
    "        heatmap_transformer = tf.squeeze(heatmap_transformer)\n",
    "        \n",
    "        # Normalize and reshape the heatmap\n",
    "        heatmap_transformer = tf.maximum(heatmap_transformer, 0) / tf.math.reduce_max(heatmap_transformer)\n",
    "        heatmap_transformer = tf.reshape(heatmap_transformer, (7, 7))\n",
    "        heatmap_transformer = heatmap_transformer.numpy()\n",
    "\n",
    "        superimposed_transformer = save_and_display_gradcam(img_path_str, heatmap_transformer)\n",
    "        transformer_pred_idx = np.argmax(transformer_model.predict(img_array_transformer_norm)[0])\n",
    "        \n",
    "        axes[2].imshow(superimposed_transformer)\n",
    "        axes[2].set_title(f\"Transformer (Swin)\\nPrediction: {CLASS_NAMES[transformer_pred_idx]}\")\n",
    "        axes[2].axis(\"off\")\n",
    "    else:\n",
    "        print(\"❌ Gradient for Transformer was None. Could not generate heatmap.\")\n",
    "        axes[2].text(0.5, 0.5, 'Failed to generate Transformer heatmap', ha='center', va='center')\n",
    "        axes[2].set_title(\"Transformer (Swin)\")\n",
    "        axes[2].axis(\"off\")\n",
    "else:\n",
    "    axes[2].text(0.5, 0.5, 'Transformer model not loaded', ha='center', va='center')\n",
    "    axes[2].set_title(\"Transformer (Swin)\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    \"\"\"Superimposes the heatmap on the original image.\"\"\"\n",
    "    img = tf.keras.utils.load_img(img_path)\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    jet_heatmap = tf.keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.utils.img_to_array(jet_heatmap)\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.utils.array_to_img(superimposed_img)\n",
    "    superimposed_img.save(cam_path)\n",
    "    return superimposed_img\n",
    "\n",
    "# --- 4. GENERATE AND DISPLAY VISUALIZATIONS ---\n",
    "print(\"\\n--- Section 4: Generating and Displaying Visualizations ---\")\n",
    "\n",
    "# Find a few sample images to test\n",
    "sample_image_paths = []\n",
    "for class_name in CLASS_NAMES:\n",
    "    try:\n",
    "        sample_image_paths.append(list((test_dir / class_name).glob(\"*.jpg\"))[0])\n",
    "    except IndexError:\n",
    "        print(f\"Warning: No images found for class {class_name} in the test set.\")\n",
    "\n",
    "# For ResNet50V2, we find the last convolutional layer name\n",
    "last_conv_layer_name_cnn = None\n",
    "if cnn_model:\n",
    "    # Find the ResNet base model inside the loaded model\n",
    "    base_model = None\n",
    "    for layer in cnn_model.layers:\n",
    "        if isinstance(layer, tf.keras.Model):  # ResNet50V2 is itself a Model\n",
    "            base_model = layer\n",
    "            break\n",
    "\n",
    "    if base_model:\n",
    "        for layer in reversed(base_model.layers):\n",
    "            if len(layer.output.shape) == 4:  # Conv layer\n",
    "                last_conv_layer_name_cnn = layer.name\n",
    "                break\n",
    "    print(f\"Found last conv layer for CNN: {last_conv_layer_name_cnn}\")\n",
    "\n",
    "# For Swin Transformer, we use the output of our custom backbone layer\n",
    "# Note: Grad-CAM on transformers is an active area of research. This is an approximation.\n",
    "# --- Find the Transformer backbone layer name dynamically ---\n",
    "last_layer_name_transformer = None # Initialize to None\n",
    "\n",
    "if transformer_model:\n",
    "    # Loop through the layers of the loaded transformer model\n",
    "    for layer in transformer_model.layers:\n",
    "        # Check if the current layer is your custom SwinBackboneLayer\n",
    "        if isinstance(layer, SwinBackboneLayer):\n",
    "            last_layer_name_transformer = layer.name # Get its actual name\n",
    "            break # Exit the loop once found\n",
    "\n",
    "# Check if the layer was found before proceeding\n",
    "if last_layer_name_transformer:\n",
    "    print(f\"✅ Successfully found Swin backbone layer: '{last_layer_name_transformer}'\")\n",
    "else:\n",
    "    print(\"❌ Warning: Could not find SwinBackboneLayer in the transformer model.\")\n",
    "\n",
    "# Generate and plot the comparisons\n",
    "for img_path in sample_image_paths:\n",
    "    img_path_str = str(img_path)\n",
    "    true_class = os.path.basename(os.path.dirname(img_path_str))\n",
    "    print(f\"\\n--- Processing image: {os.path.basename(img_path_str)} (True Class: {true_class}) ---\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    original_img = tf.keras.utils.load_img(img_path_str, target_size=IMG_SIZE)\n",
    "    axes[0].imshow(original_img)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # --- CNN Visualization ---\n",
    "    if cnn_model and last_conv_layer_name_cnn:\n",
    "        img_array_cnn = get_img_array(img_path_str, size=IMG_SIZE)\n",
    "        # Preprocess for ResNet50V2 (it has a built-in rescaling layer)\n",
    "        print(f\"Generating Grad-CAM for image: {os.path.basename(img_path_str)}\")\n",
    "        heatmap_cnn = make_gradcam_heatmap(img_array_cnn, cnn_model, last_conv_layer_name_cnn)\n",
    "        if heatmap_cnn is not None:\n",
    "            try:\n",
    "                superimposed_cnn = save_and_display_gradcam(img_path_str, heatmap_cnn)\n",
    "                cnn_pred_idx = np.argmax(cnn_model.predict(img_array_cnn)[0])\n",
    "                axes[1].imshow(superimposed_cnn)\n",
    "                axes[1].set_title(f\"CNN (ResNet50V2)\\nPrediction: {CLASS_NAMES[cnn_pred_idx]}\")\n",
    "                axes[1].axis(\"off\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error in save_and_display_gradcam: {e}\")\n",
    "                axes[1].text(0.5, 0.5, f'Failed to process CNN heatmap: {e}', ha='center', va='center')\n",
    "                axes[1].set_title(\"CNN (ResNet50V2)\")\n",
    "                axes[1].axis(\"off\")\n",
    "        else:\n",
    "            print(\"Grad-CAM heatmap is None, skipping visualization.\")\n",
    "            axes[1].text(0.5, 0.5, 'Failed to generate CNN heatmap', ha='center', va='center')\n",
    "            axes[1].set_title(\"CNN (ResNet50V2)\")\n",
    "            axes[1].axis(\"off\")\n",
    "    else:\n",
    "        print(\"CNN model or last_conv_layer_name_cnn not available.\")\n",
    "        axes[1].text(0.5, 0.5, 'CNN model not loaded or layer not found', ha='center', va='center')\n",
    "        axes[1].set_title(\"CNN (ResNet50V2)\")\n",
    "        axes[1].axis(\"off\")\n",
    "        \n",
    "    # --- Transformer Visualization ---\n",
    "    if transformer_model:\n",
    "        img_array_transformer = get_img_array(img_path_str, size=IMG_SIZE)\n",
    "        # The Swin Transformer expects inputs normalized to [0, 1]\n",
    "        img_array_transformer_norm = img_array_transformer / 255.0\n",
    "\n",
    "        # For transformers, we use a different approach for the heatmap\n",
    "        grad_model_transformer = tf.keras.models.Model(\n",
    "            transformer_model.inputs,\n",
    "            [transformer_model.get_layer(last_layer_name_transformer).output, transformer_model.output]\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            transformer_output, preds = grad_model_transformer(img_array_transformer_norm)\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "            class_channel = preds[:, pred_index]\n",
    "        grads = tape.gradient(class_channel, transformer_output)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 2))\n",
    "        transformer_output = transformer_output[0]\n",
    "        heatmap_transformer = transformer_output @ pooled_grads[..., tf.newaxis]\n",
    "        heatmap_transformer = tf.squeeze(heatmap_transformer)\n",
    "        heatmap_transformer = tf.maximum(heatmap_transformer, 0) / tf.math.reduce_max(heatmap_transformer)\n",
    "        # The output is a sequence of 49 patches, so we reshape it to a 7x7 grid\n",
    "        heatmap_transformer = tf.reshape(heatmap_transformer, (7, 7))\n",
    "        heatmap_transformer = heatmap_transformer.numpy()\n",
    "\n",
    "        superimposed_transformer = save_and_display_gradcam(img_path_str, heatmap_transformer)\n",
    "        transformer_pred_idx = np.argmax(transformer_model.predict(img_array_transformer_norm)[0])\n",
    "        axes[2].imshow(superimposed_transformer)\n",
    "        axes[2].set_title(f\"Transformer (Swin)\\nPrediction: {CLASS_NAMES[transformer_pred_idx]}\")\n",
    "        axes[2].axis(\"off\")\n",
    "    else:\n",
    "        axes[2].text(0.5, 0.5, 'Transformer model not loaded', ha='center', va='center')\n",
    "        axes[2].set_title(\"Transformer (Swin)\")\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Interpretability Analysis Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb9a86dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,245</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │        \u001b[38;5;34m10,245\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,595,537</span> (90.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,595,537\u001b[0m (90.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,245</span> (40.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,245\u001b[0m (40.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> (89.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,564,800\u001b[0m (89.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,492</span> (80.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m20,492\u001b[0m (80.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (1, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "cnn_model = tf.keras.models.load_model(\"papaya_disease_resnet50v2.keras\")\n",
    "cnn_model.summary()\n",
    "dummy_input = tf.zeros((1, 224, 224, 3))\n",
    "output = cnn_model(dummy_input)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
